---
layout: post
title:  Transformer distiled, Part 1 of 2
categories: [HTML,Code]
excerpt: scaled dot-product, softmax and multi-head attention, linear layers, learned embeddings
categories: [ML, Transformer]
---

# Scaled dot-product

# Softmax and multi-head attention

# Linear layers

# Learned Embeddings
