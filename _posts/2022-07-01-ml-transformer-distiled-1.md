---
layout: post
title:  Transformer distiled, Part 1 of 2
excerpt: scaled dot-product, softmax and multi-head attention, linear layers, learned embeddings
categories: [ml, theory, transformer, dot-product, softmax, attention, linear, embedding]
---

# Scaled dot-product

# Softmax and multi-head attention

# Linear layers

# Learned Embeddings
